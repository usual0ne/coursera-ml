import pandas as pd
import numpy as np

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ° advertising.csv Ğ² Ğ¾Ğ±ÑŠĞµĞºÑ‚ pandas DataFrame.
adver_data = pd.read_csv('advertising.csv')

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ¼Ğ°ÑÑĞ¸Ğ²Ñ‹ NumPy X Ğ¸Ğ· ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ² TV, Radio Ğ¸ Newspaper Ğ¸ y - Ğ¸Ğ· ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ° Sales.
# # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚ values Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° pandas DataFrame.
X = adver_data[['TV', 'Radio', 'Newspaper']].values
y = adver_data.Sales.values

# ĞÑ‚Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ X, Ğ²Ñ‹Ñ‡Ñ‚Ñ Ğ¸Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ¿Ğ¾ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼Ñƒ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñƒ
# Ğ¸ Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ğ² Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ½Ğ° ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ.
# Ğ”Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ mean Ğ¸ std Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² NumPy (Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ std Ğ² Pandas Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒÑÑ).
# ĞĞ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ, Ñ‡Ñ‚Ğ¾ Ğ² numpy Ğ²Ñ‹Ğ·Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ .mean() Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼ Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ°,
# Ğ° Ğ½Ğµ Ğ¿Ğ¾ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ°Ğ¼, ĞºĞ°Ğº Ğ² pandas.
# Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ°Ğ¼, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ axis.
means, stds = np.mean(X, axis=0), np.std(X, axis=0)
X = (X-means)/stds

# Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğº Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ğµ X ÑÑ‚Ğ¾Ğ»Ğ±ĞµÑ† Ğ¸Ğ· ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ hstack, ones Ğ¸ reshape Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ NumPy.
# Ğ’ĞµĞºÑ‚Ğ¾Ñ€ Ğ¸Ğ· ĞµĞ´Ğ¸Ğ½Ğ¸Ñ† Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚  ğ‘¤0  Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸.
X = np.hstack((X, np.ones((200, 1))))

# Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ mserror - ÑÑ€ĞµĞ´Ğ½ĞµĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½ÑƒÑ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ°.
# ĞĞ½Ğ° Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ´Ğ²Ğ° Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ° - Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Series y (Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°) Ğ¸ y_pred (Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ).
# ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ² ÑÑ‚Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ñ†Ğ¸ĞºĞ»Ñ‹ - Ñ‚Ğ¾Ğ³Ğ´Ğ° Ğ¾Ğ½Ğ° Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ½ĞµÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹.
def mserror(y, y_pred):
    return np.mean((y_pred - y)**2)

# Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ normal_equation, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ğ°Ğ¼ (Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ°Ğ¼ NumPy) X Ğ¸ y Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ²ĞµÑĞ¾Ğ²  ğ‘¤
# ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ ÑƒÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸.
def normal_equation(X, y):
    a = np.dot(X.T, X) # Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ»ĞµĞ²ÑƒÑ Ñ‡Ğ°ÑÑ‚ÑŒ
    b = np.dot(X.T, y) # Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ¿Ñ€Ğ°Ğ²ÑƒÑ Ñ‡Ğ°ÑÑ‚ÑŒ
    res = np.linalg.solve(a, b) # Ñ€ĞµÑˆĞ°ĞµĞ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ
    return res

# ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ linear_prediction, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñƒ X Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ²ĞµÑĞ¾Ğ² Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ w,
# Ğ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¾Ğ² Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ² Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ X Ñ Ğ²ĞµÑĞ°Ğ¼Ğ¸ w.
def linear_prediction(X, w):
    return X.dot(w)

# ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ stochastic_gradient_step, Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒÑÑ‰ÑƒÑ ÑˆĞ°Ğ³ ÑÑ‚Ğ¾Ñ…Ğ°ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ° Ğ´Ğ»Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸.
# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñƒ X, Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ° y Ğ¸ w, Ñ‡Ğ¸ÑĞ»Ğ¾ train_ind - Ğ¸Ğ½Ğ´ĞµĞºÑ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ (ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ X),
# Ğ¿Ğ¾ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼Ñƒ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ÑÑ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑĞ¾Ğ², Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾  ğœ‚  (eta) - ÑˆĞ°Ğ³ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ° (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ eta=0.01).
# Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ¼ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ²ĞµÑĞ¾Ğ². ĞĞ°ÑˆĞ° Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ²Ğ½Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ° Ğ´Ğ»Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ 3 Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°Ğ¼Ğ¸,
# Ğ½Ğ¾ Ğ½ĞµÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ², Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑÑ‚Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ.
def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):
    N = X.shape[0]  # Ğ²ÑĞµĞ³Ğ¾ Ğ¾Ğ±ÑŒĞµĞºÑ‚Ğ¾Ğ² (Ğ½Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°)
    x = X[train_ind]  # Ñ‚ĞµĞºÑƒÑˆĞ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ k Ğ¾Ğ±ÑŒĞµĞºÑ‚
    y_pred = linear_prediction(x, w)  # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğº ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŒĞµĞºÑ‚Ğ°
    rs = (y_pred - y[train_ind])  # Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ñ‹Ğ¹ Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº Ğ´Ğ»Ñ k Ğ¾Ğ±ÑŒĞµĞºÑ‚Ğ°
    grad0 = 2.0 / N * x[0] * rs
    grad1 = 2.0 / N * x[1] * rs
    grad2 = 2.0 / N * x[2] * rs
    grad3 = 2.0 / N * x[3] * rs
    return w - eta * np.array([grad0, grad1, grad2, grad3])

# ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ stochastic_gradient_descent, Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒÑÑ‰ÑƒÑ ÑÑ‚Ğ¾Ñ…Ğ°ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ÑĞ¿ÑƒÑĞº Ğ´Ğ»Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸.
# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:
#
# X - Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ğ°, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ°Ñ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ.
# y - Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°.
# w_init - Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ²ĞµÑĞ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
# eta - ÑˆĞ°Ğ³ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ° (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 0.01).
# max_iter - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ° (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 10000).
# max_weight_dist - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞµĞ²ĞºĞ»Ğ¸Ğ´Ğ¾Ğ²Ğ¾ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ²ĞµÑĞ¾Ğ² Ğ½Ğ° ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸ÑÑ… Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ°,
# Ğ¿Ñ€Ğ¸ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¿Ñ€ĞµĞºÑ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 1e-8).
# seed - Ñ‡Ğ¸ÑĞ»Ğ¾, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ğ¾Ğµ Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿ÑĞµĞ²Ğ´Ğ¾ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… Ñ‡Ğ¸ÑĞµĞ» (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 42).
# verbose - Ñ„Ğ»Ğ°Ğ³ Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸, Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ False).
# ĞĞ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€ (ÑĞ¿Ğ¸ÑĞ¾Ğº) Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒÑÑ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸.
# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ²ĞµÑĞ¾Ğ²  ğ‘¤ , Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ (ÑĞ¿Ğ¸ÑĞ¾Ğº) Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº.
def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,
                                min_weight_dist=1e-8, seed=42, verbose=False):
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ²ĞµÑĞ¾Ğ² Ğ½Ğ° ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ…
    # Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸ÑÑ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ¼.
    weight_dist = np.inf
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ²ĞµÑĞ¾Ğ²
    w = w_init
    # Ğ¡ÑĞ´Ğ° Ğ±ÑƒĞ´ĞµĞ¼ Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
    errors = []
    # Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸Ğº Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
    iter_num = 0
    # Ğ‘ÑƒĞ´ĞµĞ¼ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ¿ÑĞµĞ²Ğ´Ğ¾ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ñ‡Ğ¸ÑĞ»Ğ°
    # (Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ²ĞµÑĞ°), Ğ° Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    # ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿ÑĞµĞ²Ğ´Ğ¾ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… Ñ‡Ğ¸ÑĞµĞ» Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ seed.
    np.random.seed(seed)

    # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ†Ğ¸ĞºĞ»
    while weight_dist > min_weight_dist and iter_num < max_iter:
        # Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ĞµĞ¼ Ğ¿ÑĞµĞ²Ğ´Ğ¾ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ğ´ĞµĞºÑ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸
        random_ind = np.random.randint(X.shape[0])
        # Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ²ĞµÑĞ¾Ğ²
        w = stochastic_gradient_step(X, y, w, random_ind, eta)
        # Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ²ÑĞµÑ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
        errors.append(mserror(y[random_ind], X[random_ind].dot(w)))
        iter_num += 1

    return w, errors
